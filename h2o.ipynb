{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할(폴더) 구분\n",
    "data_splits = [\"train\", \"test\"]\n",
    "\n",
    "# 각 데이터 유형별 폴더명, 파일 접미사, 변수 접두어 설정\n",
    "data_categories = {\n",
    "    \"회원정보\": {\"folder\": \"1.회원정보\", \"suffix\": \"회원정보\", \"var_prefix\": \"customer\"},\n",
    "    \"신용정보\": {\"folder\": \"2.신용정보\", \"suffix\": \"신용정보\", \"var_prefix\": \"credit\"},\n",
    "    \"승인매출정보\": {\"folder\": \"3.승인매출정보\", \"suffix\": \"승인매출정보\", \"var_prefix\": \"sales\"},\n",
    "    \"청구정보\": {\"folder\": \"4.청구입금정보\", \"suffix\": \"청구정보\", \"var_prefix\": \"billing\"},\n",
    "    \"잔액정보\": {\"folder\": \"5.잔액정보\", \"suffix\": \"잔액정보\", \"var_prefix\": \"balance\"},\n",
    "    \"채널정보\": {\"folder\": \"6.채널정보\", \"suffix\": \"채널정보\", \"var_prefix\": \"channel\"},\n",
    "    \"마케팅정보\": {\"folder\": \"7.마케팅정보\", \"suffix\": \"마케팅정보\", \"var_prefix\": \"marketing\"},\n",
    "    \"성과정보\": {\"folder\": \"8.성과정보\", \"suffix\": \"성과정보\", \"var_prefix\": \"performance\"}\n",
    "}\n",
    "\n",
    "# 2018년 7월부터 12월까지의 월 리스트\n",
    "months = ['07', '08', '09', '10', '11', '12']\n",
    "\n",
    "for split in data_splits:\n",
    "    for category, info in data_categories.items():\n",
    "        folder = info[\"folder\"]\n",
    "        suffix = info[\"suffix\"]\n",
    "        var_prefix = info[\"var_prefix\"]\n",
    "\n",
    "        for month in months:\n",
    "            # 파일명 형식: 2018{month}_{split}_{suffix}.parquet\n",
    "            file_path = f\"open/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
    "            # 변수명 형식: {var_prefix}_{split}_{month}\n",
    "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
    "            globals()[variable_name] = pd.read_parquet(file_path)\n",
    "            print(f\"{variable_name} is loaded from {file_path}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 유형별 설정 \n",
    "info_categories = [\"customer\", \"credit\", \"sales\", \"billing\", \"balance\", \"channel\", \"marketing\", \"performance\"]\n",
    "\n",
    "# 월 설정\n",
    "months = ['07', '08', '09', '10', '11', '12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train ####\n",
    "\n",
    "# 각 유형별로 월별 데이터를 합쳐서 새로운 변수에 저장\n",
    "train_dfs = {}\n",
    "\n",
    "for prefix in info_categories:\n",
    "    # globals()에서 동적 변수명으로 데이터프레임들을 가져와 리스트에 저장\n",
    "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
    "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
    "    gc.collect()\n",
    "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
    "\n",
    "\n",
    "customer_train_df = train_dfs[\"customer_train_df\"]\n",
    "credit_train_df   = train_dfs[\"credit_train_df\"]\n",
    "sales_train_df    = train_dfs[\"sales_train_df\"]\n",
    "billing_train_df  = train_dfs[\"billing_train_df\"]\n",
    "balance_train_df  = train_dfs[\"balance_train_df\"]\n",
    "channel_train_df  = train_dfs[\"channel_train_df\"]\n",
    "marketing_train_df= train_dfs[\"marketing_train_df\"]\n",
    "performance_train_df = train_dfs[\"performance_train_df\"]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test ####\n",
    "\n",
    "# test 데이터에 대해 train과 동일한 방법 적용\n",
    "test_dfs = {}\n",
    "\n",
    "for prefix in info_categories:\n",
    "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
    "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
    "    gc.collect()\n",
    "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
    "\n",
    "\n",
    "customer_test_df = test_dfs[\"customer_test_df\"]\n",
    "credit_test_df   = test_dfs[\"credit_test_df\"]\n",
    "sales_test_df    = test_dfs[\"sales_test_df\"]\n",
    "billing_test_df  = test_dfs[\"billing_test_df\"]\n",
    "balance_test_df  = test_dfs[\"balance_test_df\"]\n",
    "channel_test_df  = test_dfs[\"channel_test_df\"]\n",
    "marketing_test_df= test_dfs[\"marketing_test_df\"]\n",
    "performance_test_df = test_dfs[\"performance_test_df\"]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train ####\n",
    "\n",
    "train_df = customer_train_df.merge(credit_train_df, on=['기준년월', 'ID'], how='left')\n",
    "print(\"Step1 저장 완료: train_step1, shape:\", train_df.shape)\n",
    "del customer_train_df, credit_train_df\n",
    "gc.collect()\n",
    "\n",
    "# 이후 merge할 데이터프레임 이름과 단계 정보를 리스트에 저장\n",
    "merge_list = [\n",
    "    (\"sales_train_df\",    \"Step2\"),\n",
    "    (\"billing_train_df\",  \"Step3\"),\n",
    "    (\"balance_train_df\",  \"Step4\"),\n",
    "    (\"channel_train_df\",  \"Step5\"),\n",
    "    (\"marketing_train_df\",\"Step6\"),\n",
    "    (\"performance_train_df\", \"최종\")\n",
    "]\n",
    "\n",
    "# 나머지 단계 merge\n",
    "for df_name, step in merge_list:\n",
    "    # globals()로 동적 변수 접근하여 merge 수행\n",
    "    train_df = train_df.merge(globals()[df_name], on=['기준년월', 'ID'], how='left')\n",
    "    print(f\"{step} 저장 완료: train_{step}, shape:\", train_df.shape)\n",
    "    # 사용한 변수는 메모리 해제를 위해 삭제\n",
    "    del globals()[df_name]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test ####\n",
    "\n",
    "test_df = customer_test_df.merge(credit_test_df, on=['기준년월', 'ID'], how='left')\n",
    "print(\"Step1 저장 완료: test_step1, shape:\", test_df.shape)\n",
    "del customer_test_df, credit_test_df\n",
    "gc.collect()\n",
    "\n",
    "# 이후 merge할 데이터프레임 이름과 단계 정보를 리스트에 저장\n",
    "merge_list = [\n",
    "    (\"sales_test_df\",    \"Step2\"),\n",
    "    (\"billing_test_df\",  \"Step3\"),\n",
    "    (\"balance_test_df\",  \"Step4\"),\n",
    "    (\"channel_test_df\",  \"Step5\"),\n",
    "    (\"marketing_test_df\",\"Step6\"),\n",
    "    (\"performance_test_df\", \"최종\")\n",
    "]\n",
    "\n",
    "# 나머지 단계 merge\n",
    "for df_name, step in merge_list:\n",
    "    # globals()로 동적 변수 접근하여 merge 수행\n",
    "    test_df = test_df.merge(globals()[df_name], on=['기준년월', 'ID'], how='left')\n",
    "    print(f\"{step} 저장 완료: test_{step}, shape:\", test_df.shape)\n",
    "    # 사용한 변수는 메모리 해제를 위해 삭제\n",
    "    del globals()[df_name]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
    "\n",
    "X = train_df[feature_cols].copy()\n",
    "y = train_df[\"Segment\"].copy()\n",
    "\n",
    "# 타깃 라벨 인코딩\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "X_test = test_df.copy()\n",
    "\n",
    "encoders = {}  # 각 컬럼별 encoder 저장\n",
    "\n",
    "for col in categorical_features:\n",
    "    le_train = LabelEncoder()\n",
    "    X[col] = le_train.fit_transform(X[col])\n",
    "    encoders[col] = le_train\n",
    "    unseen_labels_val = set(X_test[col]) - set(le_train.classes_)\n",
    "    if unseen_labels_val:\n",
    "        le_train.classes_ = np.append(le_train.classes_, list(unseen_labels_val))\n",
    "    X_test[col] = le_train.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/workspace/data/dacon/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path + \"merge_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"target\"  # 대회 타겟 컬럼\n",
    "features = [col for col in train_df.columns if col != target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O 서버 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is (4 months and 18 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>20 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Seoul</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>4 months and 18 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_JINWOO_yg7oyq</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>15.51 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.8 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         20 secs\n",
       "H2O_cluster_timezone:       Asia/Seoul\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    4 months and 18 days\n",
       "H2O_cluster_name:           H2O_from_python_JINWOO_yg7oyq\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    15.51 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.8 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🚀 H2O 서버 시작\n",
    "h2o.init(max_mem_size=\"16G\", nthreads=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 데이터 실행 (메모리 부족)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ H2O AutoML 실행 (F1 Score 최적화)\n",
    "df_h2o = h2o.H2OFrame(train_df)\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=7200,  # 2시간 제한\n",
    "    max_models=20,\n",
    "    stopping_metric=\"F1\",\n",
    "    balance_classes=True,\n",
    "    seed=42\n",
    ")\n",
    "aml.train(x=features, y=target, training_frame=df_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플링 데이터 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ RAM 최적화: 샘플링 적용 (50% 데이터만 사용)\n",
    "train_df_sampled = train_df.sample(frac=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치가 있는 컬럼 목록:\n",
      "Index(['최종유효년월_신용_이용가능', '최종유효년월_신용_이용', '최종카드발급일자', 'RV신청일자',\n",
      "       '최종카드론_금융상환방식코드', '최종카드론_대출일자', '연체일자_B0M', '혜택수혜율_R3M', '혜택수혜율_B0M'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 결측치가 있는 컬럼 확인\n",
    "missing_cols = train_df_sampled.columns[train_df_sampled.isna().sum() > 0]\n",
    "\n",
    "# 결측치가 있는 컬럼 출력\n",
    "print(\"결측치가 있는 컬럼 목록:\")\n",
    "print(missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_cleaned = train_df_sampled.drop(columns=missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ RAM 최적화: H2OFrame 변환 시 chunk_size 설정\n",
    "df_h2o = h2o.H2OFrame(train_df_cleaned)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |█\n",
      "15:16:35.512: AutoML: XGBoost is not available; skipping it.\n",
      "15:16:35.607: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "\n",
      "████\n",
      "15:17:44.738: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.738: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:44.763: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.763: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:44.781: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.782: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:44.800: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.800: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:44.819: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.819: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:44.834: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.834: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:44.847: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.847: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:44.865: _train param, Dropping bad and constant columns: [시장연체상환여부_R3M, 증감_RP건수_건강_전월, 이용건수_당사기타_B0M, 이용개월수_당사페이_R6M, 이용금액_당사기타_R6M, 상품관련면제카드수_B0M, 할인금액_기본연회비_B0M, RP건수_건강_B0M, RP건수_유선방송_B0M, 이용건수_당사페이_R3M, 이용금액_당사기타_B0M, 할부건수_부분_3M_R12M, 연회비할인카드수_B0M, 이용건수_당사페이_R6M, 이용금액_당사페이_R3M, 할인금액_제휴연회비_B0M, 기타면제카드수_B0M, 이용금액_당사기타_R3M, RP후경과월_건강, 이용건수_당사기타_R6M, 이용건수_당사페이_B0M, 우수회원면제카드수_B0M, 임직원면제카드수_B0M, 할부건수_부분_14M_R12M, 할부금액_부분_3M_R12M, 시장연체상환여부_R6M, 할부건수_부분_6M_R12M, 납부_렌탈료이용금액, 이용금액_부분무이자_B0M, 납부_유선방송이용금액, 이용건수_부분무이자_B0M, 할부금액_부분_6M_R12M, 이용카드수_체크_가족, 여유_여행이용금액, 증감_RP건수_유선방송_전월, 이용금액_당사페이_R6M, 이용금액_R3M_체크_가족, 납부_건강연금이용금액, RP후경과월_유선방송, 이용건수_당사기타_R3M, 이용금액_당사페이_B0M]\n",
      "15:17:44.865: _stopping_metric param, Stopping metric cannot be mean_per_class_error for regression.\n",
      "15:17:47.113: GBM_grid_1_AutoML_1_20250320_151600 [GBM Grid Search] failed: water.exceptions.H2OGridException: Aborting Grid search after too many consecutive model failures.\n",
      "15:17:49.99: DeepLearning_grid_1_AutoML_1_20250320_151600 [DeepLearning Grid Search] failed: water.exceptions.H2OGridException: Aborting Grid search after too many consecutive model failures.\n",
      "\n",
      " (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000132d4ffffffff$_966ea47535242a919e83cd2ef2a14eb5 failed with an exception: water.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\nstacktrace: \nwater.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\r\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:776)\r\n\tat ai.h2o.automl.AutoML.run(AutoML.java:494)\r\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:33)\r\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1704)\r\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\r\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\r\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\r\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\r\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# ✅ H2O AutoML 실행\u001b[39;00m\n\u001b[0;32m     11\u001b[0m aml \u001b[38;5;241m=\u001b[39m H2OAutoML(max_runtime_secs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3600\u001b[39m, stopping_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_per_class_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, balance_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43maml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_h2o\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ✅ 결과 확인\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(aml\u001b[38;5;241m.\u001b[39mleaderboard)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\h2o\\automl\\_estimator.py:682\u001b[0m, in \u001b[0;36mH2OAutoML.train\u001b[1;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[0;32m    680\u001b[0m poll_updates \u001b[38;5;241m=\u001b[39m ft\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_training_updates, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbosity, state\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_updates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    684\u001b[0m     poll_updates(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\h2o\\job.py:88\u001b[0m, in \u001b[0;36mH2OJob.poll\u001b[1;34m(self, poll_updates)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob, \u001b[38;5;28mdict\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstacktrace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob)):\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob with key \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m failed with an exception: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mstacktrace: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstacktrace\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob with key \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failed with an exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception))\n",
      "\u001b[1;31mOSError\u001b[0m: Job with key $03017f00000132d4ffffffff$_966ea47535242a919e83cd2ef2a14eb5 failed with an exception: water.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\nstacktrace: \nwater.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\r\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:776)\r\n\tat ai.h2o.automl.AutoML.run(AutoML.java:494)\r\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:33)\r\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1704)\r\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\r\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\r\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\r\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\r\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ✅ Feature Selection: 중요 컬럼만 학습\n",
    "features = df_h2o.columns[:500]  # 메모리 초과 방지\n",
    "\n",
    "# ✅ H2O AutoML 실행\n",
    "aml = H2OAutoML(max_runtime_secs=3600, stopping_metric=\"mean_per_class_error\", balance_classes=True)\n",
    "aml.train(x=features, y=target, training_frame=df_h2o)\n",
    "\n",
    "# ✅ 결과 확인\n",
    "print(aml.leaderboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
