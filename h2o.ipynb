{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶„í• (í´ë”) êµ¬ë¶„\n",
    "data_splits = [\"train\", \"test\"]\n",
    "\n",
    "# ê° ë°ì´í„° ìœ í˜•ë³„ í´ë”ëª…, íŒŒì¼ ì ‘ë¯¸ì‚¬, ë³€ìˆ˜ ì ‘ë‘ì–´ ì„¤ì •\n",
    "data_categories = {\n",
    "    \"íšŒì›ì •ë³´\": {\"folder\": \"1.íšŒì›ì •ë³´\", \"suffix\": \"íšŒì›ì •ë³´\", \"var_prefix\": \"customer\"},\n",
    "    \"ì‹ ìš©ì •ë³´\": {\"folder\": \"2.ì‹ ìš©ì •ë³´\", \"suffix\": \"ì‹ ìš©ì •ë³´\", \"var_prefix\": \"credit\"},\n",
    "    \"ìŠ¹ì¸ë§¤ì¶œì •ë³´\": {\"folder\": \"3.ìŠ¹ì¸ë§¤ì¶œì •ë³´\", \"suffix\": \"ìŠ¹ì¸ë§¤ì¶œì •ë³´\", \"var_prefix\": \"sales\"},\n",
    "    \"ì²­êµ¬ì •ë³´\": {\"folder\": \"4.ì²­êµ¬ì…ê¸ˆì •ë³´\", \"suffix\": \"ì²­êµ¬ì •ë³´\", \"var_prefix\": \"billing\"},\n",
    "    \"ì”ì•¡ì •ë³´\": {\"folder\": \"5.ì”ì•¡ì •ë³´\", \"suffix\": \"ì”ì•¡ì •ë³´\", \"var_prefix\": \"balance\"},\n",
    "    \"ì±„ë„ì •ë³´\": {\"folder\": \"6.ì±„ë„ì •ë³´\", \"suffix\": \"ì±„ë„ì •ë³´\", \"var_prefix\": \"channel\"},\n",
    "    \"ë§ˆì¼€íŒ…ì •ë³´\": {\"folder\": \"7.ë§ˆì¼€íŒ…ì •ë³´\", \"suffix\": \"ë§ˆì¼€íŒ…ì •ë³´\", \"var_prefix\": \"marketing\"},\n",
    "    \"ì„±ê³¼ì •ë³´\": {\"folder\": \"8.ì„±ê³¼ì •ë³´\", \"suffix\": \"ì„±ê³¼ì •ë³´\", \"var_prefix\": \"performance\"}\n",
    "}\n",
    "\n",
    "# 2018ë…„ 7ì›”ë¶€í„° 12ì›”ê¹Œì§€ì˜ ì›” ë¦¬ìŠ¤íŠ¸\n",
    "months = ['07', '08', '09', '10', '11', '12']\n",
    "\n",
    "for split in data_splits:\n",
    "    for category, info in data_categories.items():\n",
    "        folder = info[\"folder\"]\n",
    "        suffix = info[\"suffix\"]\n",
    "        var_prefix = info[\"var_prefix\"]\n",
    "\n",
    "        for month in months:\n",
    "            # íŒŒì¼ëª… í˜•ì‹: 2018{month}_{split}_{suffix}.parquet\n",
    "            file_path = f\"open/{split}/{folder}/2018{month}_{split}_{suffix}.parquet\"\n",
    "            # ë³€ìˆ˜ëª… í˜•ì‹: {var_prefix}_{split}_{month}\n",
    "            variable_name = f\"{var_prefix}_{split}_{month}\"\n",
    "            globals()[variable_name] = pd.read_parquet(file_path)\n",
    "            print(f\"{variable_name} is loaded from {file_path}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ìœ í˜•ë³„ ì„¤ì • \n",
    "info_categories = [\"customer\", \"credit\", \"sales\", \"billing\", \"balance\", \"channel\", \"marketing\", \"performance\"]\n",
    "\n",
    "# ì›” ì„¤ì •\n",
    "months = ['07', '08', '09', '10', '11', '12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train ####\n",
    "\n",
    "# ê° ìœ í˜•ë³„ë¡œ ì›”ë³„ ë°ì´í„°ë¥¼ í•©ì³ì„œ ìƒˆë¡œìš´ ë³€ìˆ˜ì— ì €ì¥\n",
    "train_dfs = {}\n",
    "\n",
    "for prefix in info_categories:\n",
    "    # globals()ì—ì„œ ë™ì  ë³€ìˆ˜ëª…ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ë“¤ì„ ê°€ì ¸ì™€ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "    df_list = [globals()[f\"{prefix}_train_{month}\"] for month in months]\n",
    "    train_dfs[f\"{prefix}_train_df\"] = pd.concat(df_list, axis=0)\n",
    "    gc.collect()\n",
    "    print(f\"{prefix}_train_df is created with shape: {train_dfs[f'{prefix}_train_df'].shape}\")\n",
    "\n",
    "\n",
    "customer_train_df = train_dfs[\"customer_train_df\"]\n",
    "credit_train_df   = train_dfs[\"credit_train_df\"]\n",
    "sales_train_df    = train_dfs[\"sales_train_df\"]\n",
    "billing_train_df  = train_dfs[\"billing_train_df\"]\n",
    "balance_train_df  = train_dfs[\"balance_train_df\"]\n",
    "channel_train_df  = train_dfs[\"channel_train_df\"]\n",
    "marketing_train_df= train_dfs[\"marketing_train_df\"]\n",
    "performance_train_df = train_dfs[\"performance_train_df\"]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test ####\n",
    "\n",
    "# test ë°ì´í„°ì— ëŒ€í•´ trainê³¼ ë™ì¼í•œ ë°©ë²• ì ìš©\n",
    "test_dfs = {}\n",
    "\n",
    "for prefix in info_categories:\n",
    "    df_list = [globals()[f\"{prefix}_test_{month}\"] for month in months]\n",
    "    test_dfs[f\"{prefix}_test_df\"] = pd.concat(df_list, axis=0)\n",
    "    gc.collect()\n",
    "    print(f\"{prefix}_test_df is created with shape: {test_dfs[f'{prefix}_test_df'].shape}\")\n",
    "\n",
    "\n",
    "customer_test_df = test_dfs[\"customer_test_df\"]\n",
    "credit_test_df   = test_dfs[\"credit_test_df\"]\n",
    "sales_test_df    = test_dfs[\"sales_test_df\"]\n",
    "billing_test_df  = test_dfs[\"billing_test_df\"]\n",
    "balance_test_df  = test_dfs[\"balance_test_df\"]\n",
    "channel_test_df  = test_dfs[\"channel_test_df\"]\n",
    "marketing_test_df= test_dfs[\"marketing_test_df\"]\n",
    "performance_test_df = test_dfs[\"performance_test_df\"]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train ####\n",
    "\n",
    "train_df = customer_train_df.merge(credit_train_df, on=['ê¸°ì¤€ë…„ì›”', 'ID'], how='left')\n",
    "print(\"Step1 ì €ì¥ ì™„ë£Œ: train_step1, shape:\", train_df.shape)\n",
    "del customer_train_df, credit_train_df\n",
    "gc.collect()\n",
    "\n",
    "# ì´í›„ mergeí•  ë°ì´í„°í”„ë ˆì„ ì´ë¦„ê³¼ ë‹¨ê³„ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "merge_list = [\n",
    "    (\"sales_train_df\",    \"Step2\"),\n",
    "    (\"billing_train_df\",  \"Step3\"),\n",
    "    (\"balance_train_df\",  \"Step4\"),\n",
    "    (\"channel_train_df\",  \"Step5\"),\n",
    "    (\"marketing_train_df\",\"Step6\"),\n",
    "    (\"performance_train_df\", \"ìµœì¢…\")\n",
    "]\n",
    "\n",
    "# ë‚˜ë¨¸ì§€ ë‹¨ê³„ merge\n",
    "for df_name, step in merge_list:\n",
    "    # globals()ë¡œ ë™ì  ë³€ìˆ˜ ì ‘ê·¼í•˜ì—¬ merge ìˆ˜í–‰\n",
    "    train_df = train_df.merge(globals()[df_name], on=['ê¸°ì¤€ë…„ì›”', 'ID'], how='left')\n",
    "    print(f\"{step} ì €ì¥ ì™„ë£Œ: train_{step}, shape:\", train_df.shape)\n",
    "    # ì‚¬ìš©í•œ ë³€ìˆ˜ëŠ” ë©”ëª¨ë¦¬ í•´ì œë¥¼ ìœ„í•´ ì‚­ì œ\n",
    "    del globals()[df_name]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test ####\n",
    "\n",
    "test_df = customer_test_df.merge(credit_test_df, on=['ê¸°ì¤€ë…„ì›”', 'ID'], how='left')\n",
    "print(\"Step1 ì €ì¥ ì™„ë£Œ: test_step1, shape:\", test_df.shape)\n",
    "del customer_test_df, credit_test_df\n",
    "gc.collect()\n",
    "\n",
    "# ì´í›„ mergeí•  ë°ì´í„°í”„ë ˆì„ ì´ë¦„ê³¼ ë‹¨ê³„ ì •ë³´ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
    "merge_list = [\n",
    "    (\"sales_test_df\",    \"Step2\"),\n",
    "    (\"billing_test_df\",  \"Step3\"),\n",
    "    (\"balance_test_df\",  \"Step4\"),\n",
    "    (\"channel_test_df\",  \"Step5\"),\n",
    "    (\"marketing_test_df\",\"Step6\"),\n",
    "    (\"performance_test_df\", \"ìµœì¢…\")\n",
    "]\n",
    "\n",
    "# ë‚˜ë¨¸ì§€ ë‹¨ê³„ merge\n",
    "for df_name, step in merge_list:\n",
    "    # globals()ë¡œ ë™ì  ë³€ìˆ˜ ì ‘ê·¼í•˜ì—¬ merge ìˆ˜í–‰\n",
    "    test_df = test_df.merge(globals()[df_name], on=['ê¸°ì¤€ë…„ì›”', 'ID'], how='left')\n",
    "    print(f\"{step} ì €ì¥ ì™„ë£Œ: test_{step}, shape:\", test_df.shape)\n",
    "    # ì‚¬ìš©í•œ ë³€ìˆ˜ëŠ” ë©”ëª¨ë¦¬ í•´ì œë¥¼ ìœ„í•´ ì‚­ì œ\n",
    "    del globals()[df_name]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train_df.columns if col not in [\"ID\", \"Segment\"]]\n",
    "\n",
    "X = train_df[feature_cols].copy()\n",
    "y = train_df[\"Segment\"].copy()\n",
    "\n",
    "# íƒ€ê¹ƒ ë¼ë²¨ ì¸ì½”ë”©\n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "X_test = test_df.copy()\n",
    "\n",
    "encoders = {}  # ê° ì»¬ëŸ¼ë³„ encoder ì €ì¥\n",
    "\n",
    "for col in categorical_features:\n",
    "    le_train = LabelEncoder()\n",
    "    X[col] = le_train.fit_transform(X[col])\n",
    "    encoders[col] = le_train\n",
    "    unseen_labels_val = set(X_test[col]) - set(le_train.classes_)\n",
    "    if unseen_labels_val:\n",
    "        le_train.classes_ = np.append(le_train.classes_, list(unseen_labels_val))\n",
    "    X_test[col] = le_train.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë°ì´í„° í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/workspace/data/dacon/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path + \"merge_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"target\"  # ëŒ€íšŒ íƒ€ê²Ÿ ì»¬ëŸ¼\n",
    "features = [col for col in train_df.columns if col != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is (4 months and 16 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>2 mins 49 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Seoul</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>4 months and 16 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_JINWOO_u7oixc</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>15.51 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.8 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         2 mins 49 secs\n",
       "H2O_cluster_timezone:       Asia/Seoul\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    4 months and 16 days\n",
       "H2O_cluster_name:           H2O_from_python_JINWOO_u7oixc\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    15.51 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.8 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ğŸš€ H2O ì„œë²„ ì‹œì‘\n",
    "h2o.init(max_mem_size=\"16G\", nthreads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… H2O AutoML ì‹¤í–‰ (F1 Score ìµœì í™”)\n",
    "df_h2o = h2o.H2OFrame(train_df)\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=7200,  # 2ì‹œê°„ ì œí•œ\n",
    "    max_models=20,\n",
    "    stopping_metric=\"F1\",\n",
    "    balance_classes=True,\n",
    "    seed=42\n",
    ")\n",
    "aml.train(x=features, y=target, training_frame=df_h2o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
